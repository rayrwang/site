<!DOCTYPE html>
<html>
    <head>
        <title>How Adam works: Brief Guide to Optimizers</title>
        <link rel="stylesheet" type="text/css" href="/assets/style.css">
        <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>
        <link rel="icon" href="/images/icon.png" type="image/x-icon">
        <style>
            body {
                font-family: sans-serif
            }
            p {
                margin-left: 100px;
                margin-right: 100px;
            }
            img {
                margin-left: 100px;
                margin-right: 100px;
            }
        </style>
    </head>

    <body>
        <div class="main-links">
            <a id="displayName" href="https://rayrwang.com">Raymond Wang</a>
            <br>
            <a href="https://rayrwang.com">Blog</a>
            <a href="https://rayrwang.com/about">About</a>
        </div>

        <p style="font-size: 30px; margin-bottom: 10px;"><strong>(not yet complete) How Adam works: Brief Guide to Optimizers</strong></p>
        
        <p>Here's your neural network:</p>
        <p>\(
            \begin{align*}
            l = f(x, \mathbf{\theta}) \\
            l : loss \\
            f : neural net architecture \\
            x : input \\
            \mathbf{\theta} : vector of parameters
            \)</p>
        <p>And here's your gradient:</p>
        <p>\(
            \begin{align*}
            \mathbf{g} = \frac{dl}{d\mathbf{\theta}} \\
            g : gradient vector
            \)</p>
    </body>
</html>
