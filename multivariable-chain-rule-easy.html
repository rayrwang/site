<!DOCTYPE html>
<html>
    <head>
        <title>The Multivariable Chain Rule in 60 Seconds</title>
        <link rel="stylesheet" type="text/css" href="/assets/style.css">
        <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>
        <link rel="icon" href="images/icon.png" type="image/x-icon">
        <style>
            body {
                font-family: sans-serif
            }
            p {
                margin-left: 100px;
                margin-right: 100px;
            }
            img {
                margin-left: 100px;
                margin-right: 100px;
            }
        </style>
    </head>

    <body>
        <p>The multivariable chain rule is the main idea behind how the backpropagation algorithm works. Backprop is currently the most popular method for training neural networks.  </p>
        <p>It is a very simple concept.  </p>

        <p><strong>Basics</strong>  </p>
            <p>A function gets you from one variable to another.  </p>
            <img src="/images/single_to_single.svg">
            <p>\(b = b(a)\)  </p>
            <p>A function can take multiple variables as inputs, a "multivariable function."  </p>
            <img src="/images/many_to_one.svg">
            <p>\(c = c(a, b)\)  </p>
            <p>Relatedly, a variable can be the inputs for multiple functions.  </p>
            <img src="/images/one_to_two.svg">
            <p>\(
                \begin{align*}
                b = b(a) \\
                c = c(a)
                \end{align*}
                \)</p>
            <p>You can take derivatives of functions</p>
            <p>\(
                \begin{align*}
                &b = b(a) \\
                &\frac{db}{da} = \frac{d}{da} b(a)
                \end{align*}
                \)</p>
            <p>And you can take partial derivatives of multivariable functions.
                The notation is different, but they work the same as derivatives of single variable functions.
                In this post I will use the partial derivative notation for single variable functions as well,
                for simplicity/out of laziness.  </p>
            <p>\(
                \begin{align*}
                &c = c(a, b) \\
                &\frac{\partial c}{\partial a} = \frac{\partial}{\partial a} c(a, b) \\
                &\frac{\partial c}{\partial b} = \frac{\partial}{\partial b} c(a, b) \\
                \end{align*}
                \)</p>

        <p><strong>Three simple rules</strong>  </p>
            <p>The multivariable chain rule is essentially just three simple rules.  </p>
            <p>
                1. Derivatives along the same path multiply.<br>
                2. Derivatives long different paths add.<br>
                3. You must account for all paths.  
            </p>

        <p><strong>Explanation of rule 1</strong>  </p>
            <p>Take the following chain of functions:</p>
            <img src="/images/chain.svg">
            <p>\(
                \begin{align*}
                &b = b(a) \\
                &c = c(b) \\
                \end{align*}
                \)</p>
            <p>Then, in order to compute \(\frac{\partial c}{\partial a}\),
                we simply multiply the derivatives of the middle two functions.  
            </p>
            <p>\(
                \begin{align*}
                &\frac{\partial c}{\partial a} = \frac{\partial c}{\partial b} \frac{\partial b}{\partial a}
                \end{align*}
                \)</p>

        <p><strong>Explanation of rule 2</strong>  </p>
            <p>
                In this example, the derivatives from \(d\) come back together at \(a\).
            </p>
            <img src="/images/adding.svg">
            <p>\(
                \begin{align*}
                &b = b(a) \\
                &c = c(a) \\
                &d = d(b, c)
                \end{align*}
                \)</p>
            <p>
                To do this, you simply add the derivatives from the two paths.
            </p>
            <p>\(
                \begin{align*}
                &\frac{\partial d}{\partial a} = \frac{\partial d}{\partial b} \frac{\partial b}{\partial a} + \frac{\partial d}{\partial c} \frac{\partial c}{\partial a}
                \end{align*}
                \)</p>

        <p><strong>Explanation of rule 3 and an example</strong>  </p>
            <p>To calculate the derivative of one variable with respect to another,
                you must account for all the paths between them.
            </p>
            <p>In the example .</p>

        <p><strong>Appendix</strong>  </p>
            <p>Example and verifying using PyTorch.  </p>

    </body>
</html>
